30
Q:We have to capture the real-time video using Android Camera, and send them to the server, then other users would read them through the browser or something else.

I have Googled and searched at SO, and there are some examples about video stream app like:

1 Android-eye: https://github.com/Teaonly/android-eye

2 Spydroid-ipcamera:https://code.google.com/p/spydroid-ipcamera/

However it seems that they have different environments, most of the apps will start an HTTP server for stream requests, then the client will visit the page through the local network and see the video.

Then the video stream  source and the server are both the device like this:


But we need the internet support like this:


So I wonder if there are any alternative ideas.
    
===============================================================================================
35
A:I can see you have designed the three stages correctly, in your second diagram.

So what you need is to determine how to choose among these protocols and how to interface them.
 No one can give you a complete solution but having completed an enterprise project on Android Video Streaming I will try to straighten your sight towards your goal.



There are three parts in your picture, I'll elaborate from left to right:

 1. Android Streamer Device

Based on my experience, I can say Android does well sending Camera streams over RTP, due to native support, while converting your video to FLV gives you headache. (In many cases, e.g. if later you want to deliver the stream on to the Android devices.)

So I would suggest building up on something like spyDroid.

 2. Streaming Server

There are tools like Wowza Server which can get a source stream
and put it on the output of the server for other clients. I guess
VLC can do this too, via File-->Stream menu, an then putting the
RTSP video stream address from your spyDroid based app. But I have
not tried it personally.

Also it is not a hard work to implement your own streamer server.

I'll give you an example: 

For Implementation of an HLS server, you just need three things:


Video files, segmented into 10 second MPEG2 chunks. (i.e. .ts files)
An m3U8 playlist of the chunks.
A Web Server with a simple WebService that deliver the playlist to the Clients (PC, Android, iPhone, mostly every device) over HTTP. The clients will then look up the playlist file and ask for the appropriate chunks on their according timing. Because nearly all players have built-in HLS support.


 3. The Client-Side

Based on our comments, I suggest you might want to dig deeper into Android Video Streaming.

To complete a project this big, you need much more research. For example you should be able to distinguish RTP from RTSP and understand how they are related to each other.

Read my answer here to get a sense of state-of-the-art Video Streaming and please feel free to ask for more.

Hope you got the big picture of the journey ahead,

Good Luck and Have Fun
    